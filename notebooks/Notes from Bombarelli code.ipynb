{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important files:\n",
    "1. `train_vae.py`: The code for training the VAE with/without property prediction.\n",
    "2. `hyperparameters.py`: The main file, `train_vae.py` references this file for stuff like what loss functions are used, what the weights are, and a boolean for whether property prediction is done. \n",
    "3. `models.py`: Contains model architecture (`encoder_model`, `decoder_model`, `property_predictor_model`).\n",
    "\n",
    "### Input:\n",
    "With/without property prediction, the input is just one-hot encoded padded smiles strings.\n",
    "\n",
    "### Output: \n",
    "X_train, X_test, Y_train, Y_test are defined in the `vectorize_data` function in `train_vae.py`. Without property prediction, this function only returns X_train, X_test. \n",
    "\n",
    "Without property prediction, then `Y_train = []`.\n",
    "\n",
    "With property prediction, then the property data for X_train is added. \n",
    "```python\n",
    "Y_train = []\n",
    "Y_train.append(Y_reg_train)\n",
    "\n",
    "```\n",
    "The resulting outputs are stored as `model_train_targets` (in `train_vae.py`)\n",
    "```python\n",
    "model_train_targets = {'x_pred':X_train, 'z_mean_log_var':np.ones((np.shape(X_train)[0], params['hidden_dim'] * 2))}\n",
    "model_train_targets['reg_prop_pred'] = Y_train[0]\n",
    "```\n",
    "Note how even for no property prediction, it trains on two targets: 'x_pred' and 'z_mean_log_var'. \n",
    "\n",
    "### Losses:\n",
    "\n",
    "#### Loss measures:\n",
    "With/without property prediction, reconstruction loss and KL divergence are included. There is one loss for each target.\n",
    "\n",
    "In `train_vae.py` -> `main_property_run`:\n",
    "\n",
    "```python\n",
    "model_losses = {'x_pred': params['loss'], 'z_mean_log_var': kl_loss}\n",
    "```\n",
    "With property prediction, a property prediction loss is included. Looking into hyperparameters.py, this loss is 'mse'.\n",
    "\n",
    "```python\n",
    "model_losses['reg_prop_pred'] = params['reg_prop_pred_loss']. \n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### Loss weights:\n",
    "Each loss measure has a weight associated with it. The total loss is the sum of weight*loss.\n",
    "\n",
    "In `hyperparameters.py`:\n",
    "\n",
    "```python\n",
    "'xent_loss_weight': 1.0\n",
    "'kl_loss_weight': 1.0\n",
    "'prop_pred_loss_weight': 0.5\n",
    "\n",
    "```\n",
    "\n",
    "### Architecture:\n",
    "In `train_vae.py`-> `load_models` function:\n",
    "\n",
    "Recall above that there are three targets if property prediction (only regression) is selected:\n",
    "```python\n",
    "AE_PP_model = Model(x_in, model_outputs)\n",
    "model_outputs = [x_out, z_mean_log_var_output]\n",
    "model_outputs.append(reg_prop_pred)\n",
    "```\n",
    "\n",
    "\n",
    "The model is compiled and trained in `train_vae.py` -> `main_property_run`:\n",
    "\n",
    "```python\n",
    "\n",
    "##X,Y from vectorize_data function. \n",
    "X_train, X_test, Y_train, Y_test = vectorize_data(params)\n",
    "\n",
    "##As mentioned in Outputs section above, three outputs for 1. reconstruction, 2. latent_space, 3. property.\n",
    "model_train_targets = {'x_pred':X_train, 'z_mean_log_var':np.ones((np.shape(X_train)[0], params['hidden_dim'] * 2))}\n",
    "model_train_targets['reg_prop_pred'] = Y_train[0]\n",
    "\n",
    "\n",
    "##model is compiled using the three losses.\n",
    "AE_PP_model.compile(loss=model_losses,\n",
    "               loss_weights=model_loss_weights,\n",
    "               optimizer=optim,\n",
    "               metrics={'x_pred': ['categorical_accuracy',\n",
    "                    vae_anneal_metric]})\n",
    "\n",
    "##model is fit using X_train (one hot padded smiles). Different from Keras, it is fit to 'x_pred' and 'z_mean_log_var' as targets if\n",
    "##no property prediction, and those two + 'reg_prop_pred' if prop pred.\n",
    "AE_PP_model.fit(X_train, model_train_targets,\n",
    "                     batch_size=params['batch_size'],\n",
    "                     epochs=params['epochs'],\n",
    "                     initial_epoch=params['prev_epochs'],\n",
    "                     callbacks=callbacks,\n",
    "                     verbose=keras_verbose,\n",
    "     validation_data=[X_test, model_test_targets]\n",
    " )\n",
    "\n",
    "##not sure how this step works. \n",
    "encoder.save(params['encoder_weights_file'])\n",
    "decoder.save(params['decoder_weights_file'])\n",
    "property_predictor.save(params['prop_pred_weights_file'])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
